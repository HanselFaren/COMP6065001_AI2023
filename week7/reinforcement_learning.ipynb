{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf1eada-d40b-491d-bb7a-6d92a4ce3ea2",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "Outline\n",
    "1. Path finding example\n",
    "2. Getting started with Gym\n",
    "3. Designing AI agent\n",
    "4. Exercise\n",
    "5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45dd62c-d689-4876-ade9-00f4997c9e24",
   "metadata": {},
   "source": [
    "### 1. Path finding example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e066e507-89dc-4e0b-ae88-5111397c66ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Q matrix\n",
      "[[  0.    0.    0.    0.   80.    0. ]\n",
      " [  0.    0.    0.   64.    0.  100. ]\n",
      " [  0.    0.    0.   64.    0.    0. ]\n",
      " [  0.   80.   51.2   0.   80.    0. ]\n",
      " [  0.   80.   51.2   0.    0.  100. ]\n",
      " [  0.   80.    0.    0.   80.  100. ]]\n",
      "Selected path\n",
      "[2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "from locale import currency\n",
    "import numpy as np\n",
    "\n",
    "R = np.matrix([[-1,-1,-1,-1,0,-1],\n",
    "               [-1,-1,-1,0,-1,100],\n",
    "               [-1,-1,-1,0,-1,-1],\n",
    "               [-1,0,0,-1,0,-1],\n",
    "               [-1,0,0,-1,-1,100],\n",
    "               [-1,0,-1,-1,0,100]])\n",
    "\n",
    "Q=np.matrix(np.zeros([6,6]))\n",
    "\n",
    "alpha = 0.8\n",
    "\n",
    "initial_state=1\n",
    "\n",
    "def available_actions(state):\n",
    "    curr_state_row = R[state,]\n",
    "    av_act = np.where(curr_state_row>=0)[1]\n",
    "    return av_act\n",
    "\n",
    "available_act = available_actions(initial_state)\n",
    "\n",
    "def sample_next_action(available_actions_range):\n",
    "    next_action = int(np.random.choice(available_act))\n",
    "    return next_action\n",
    "\n",
    "action = sample_next_action(available_act)\n",
    "\n",
    "def update (current_state, action, alpha):\n",
    "    max_index = np.where(Q[action,]==np.max(Q[action,]))[1]\n",
    "\n",
    "    if (max_index.shape[0] > 1):\n",
    "        max_index = int (np.random.choice(max_index))\n",
    "    else:\n",
    "        max_index = max_index[0]\n",
    "    max_value = Q[action, max_index]\n",
    "\n",
    "    #Q learning formula\n",
    "    Q[current_state,action] = R[current_state, action] + alpha*max_value\n",
    "\n",
    "update(initial_state, action, alpha)\n",
    "\n",
    "# TRAINING\n",
    "for i in range (10000):\n",
    "    current_state = np.random.randint(0,int(Q.shape[0]))\n",
    "    available_act = available_actions(current_state)\n",
    "    action = sample_next_action(available_act)\n",
    "    update(current_state, action, alpha)\n",
    "\n",
    "print(\"Trained Q matrix\")\n",
    "print(Q/np.max(Q)* 100)\n",
    "\n",
    "# TESTING\n",
    "goal_state = 5\n",
    "current_state = 2\n",
    "steps = [current_state]\n",
    "\n",
    "while current_state != goal_state:\n",
    "    next_step_index = np.where(Q[current_state,]==np.max(Q[current_state,]))[1]\n",
    "    if next_step_index.shape[0] > 1:\n",
    "        next_step_index=int(np.random.choice(next_step_index))\n",
    "    else:\n",
    "        next_step_index = next_step_index[0]\n",
    "    steps.append(next_step_index)\n",
    "    current_state  =  next_step_index\n",
    "\n",
    "print(\"Selected path\")\n",
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4f664-4ca7-4657-b6d8-0feeaa1db47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 2\n",
    "print(current_state, action)\n",
    "def update (current_state, action, alpha):\n",
    "    max_index = np.where(Q[action,]==np.max(Q[action,]))[1]\n",
    "    print(Q[action,])\n",
    "    print(np.max(Q[action,]))\n",
    "    print(max_index)\n",
    "\n",
    "    if (max_index.shape[0] > 1):\n",
    "        max_index = int (np.random.choice(max_index))\n",
    "    else:\n",
    "        max_index = max_index[0]\n",
    "    max_value = Q[action, max_index]\n",
    "    print(max_value)\n",
    "\n",
    "    #Q learning formula\n",
    "    Q[current_state,action] = R[current_state, action] + alpha*max_value\n",
    "\n",
    "print(Q)\n",
    "update(initial_state, action, alpha)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f01b29bc-2f3a-4388-8ff1-d5593615c34a",
   "metadata": {},
   "source": [
    "### 2. Getting started with Gym\n",
    "\n",
    "In this part, we install the necessary packages and <br>\n",
    "1) create an environment <br>\n",
    "2) draw the current state (observation) <br>\n",
    "3) create a default loop to interact with the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e086479-3ba8-403a-b38a-be3de07e0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the library\n",
    "!pip install gymnasium\n",
    "!pip install pygame\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b53c405-bfe8-434d-8606-d267e1da60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "The action space: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "\n",
    "# Initialize environment\n",
    "env = gym.make('CartPole-v1', render_mode = 'rgb_array')\n",
    "\n",
    "# Observation and action space \n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "print(\"The observation space: {}\".format(obs_space))\n",
    "print(\"The action space: {}\".format(action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533f5ed8-10bb-43f0-a1ed-81124d11a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial observation is [0.04771857 0.01951293 0.03574747 0.02476344]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x147ce1f90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reset the environment and see the initial observation\n",
    "obs, info = env.reset()\n",
    "print(\"The initial observation is {}\".format(obs))\n",
    "\n",
    "# Draw the current state (observation)\n",
    "env_screen = env.render()\n",
    "env.close()\n",
    "\n",
    "plt.imshow(env_screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e33f16-fad6-4357-8039-cefce299d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 [-0.01934795 -0.16680086  0.01201243  0.27526724] 1.0 False False\n",
      "step: 1 [-0.02268397 -0.3620921   0.01751778  0.5717146 ] 1.0 False False\n",
      "step: 2 [-0.02992581 -0.16722013  0.02895207  0.28460142] 1.0 False False\n",
      "step: 3 [-0.03327022  0.02747718  0.03464409  0.00118855] 1.0 False False\n",
      "step: 4 [-0.03272067 -0.16812405  0.03466786  0.30459768] 1.0 False False\n",
      "step: 5 [-0.03608315 -0.36372244  0.04075982  0.6080093 ] 1.0 False False\n",
      "step: 6 [-0.0433576  -0.16919336  0.05292001  0.32843807] 1.0 False False\n",
      "step: 7 [-0.04674147 -0.3650272   0.05948877  0.6373288 ] 1.0 False False\n",
      "step: 8 [-0.05404201 -0.560926    0.07223534  0.9481367 ] 1.0 False False\n",
      "step: 9 [-0.06526054 -0.75694233  0.09119807  1.262613  ] 1.0 False False\n",
      "step: 10 [-0.08039938 -0.56309706  0.11645034  0.9998286 ] 1.0 False False\n",
      "step: 11 [-0.09166132 -0.36970785  0.13644691  0.74586844] 1.0 False False\n",
      "step: 12 [-0.09905548 -0.5664223   0.15136428  1.0781887 ] 1.0 False False\n",
      "step: 13 [-0.11038393 -0.3735879   0.17292805  0.8365757 ] 1.0 False False\n",
      "step: 14 [-0.11785568 -0.18119617  0.18965957  0.6028801 ] 1.0 False False\n",
      "step: 15 [-0.12147961 -0.37839368  0.20171717  0.94879854] 1.0 False False\n",
      "step: 16 [-0.12904748 -0.5755756   0.22069314  1.2974777 ] 1.0 True False\n"
     ]
    }
   ],
   "source": [
    "# Main (default) loop of the simulation\n",
    "for i in range(1000):\n",
    "    # get sample action from action space\n",
    "    action = env.action_space.sample() \n",
    "\n",
    "    # apply selected action \n",
    "    # get new observation and reward\n",
    "    # status if terminated or truncated, and other debug info\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    print(\"step: %d\"%i, observation, reward, terminated, truncated,)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbde283-a3df-41c3-9c34-b3f4990fa26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the current state (observation)\n",
    "env_screen = env.render()\n",
    "env.close()\n",
    "\n",
    "plt.imshow(env_screen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33efb9-3a42-46c8-bace-dbf340452b92",
   "metadata": {},
   "source": [
    "### 3. Designing AI Agent\n",
    "\n",
    "In this part, we create a class for our Agent that is not learning anything yet, <br>\n",
    "but selects his actions randomly given the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "610dc75b-110a-49c2-a613-71e1441b497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset state:  [-0.01227121 -0.04632531 -0.00631484  0.00064845]\n",
      "State at 0: [-0.01319772 -0.24135612 -0.00630187  0.2913323 ]\n",
      "1.0 [-0.01319772 -0.24135612 -0.00630187  0.2913323 ] False\n",
      "State at 1: [-1.8024843e-02 -4.3638766e-01 -4.7522088e-04  5.8202106e-01]\n",
      "1.0 [-1.8024843e-02 -4.3638766e-01 -4.7522088e-04  5.8202106e-01] False\n",
      "State at 2: [-0.02675259 -0.6315029   0.0111652   0.8745542 ]\n",
      "1.0 [-0.02675259 -0.6315029   0.0111652   0.8745542 ] False\n",
      "State at 3: [-0.03938266 -0.43653455  0.02865629  0.58540237]\n",
      "1.0 [-0.03938266 -0.43653455  0.02865629  0.58540237] False\n",
      "State at 4: [-0.04811335 -0.24182546  0.04036433  0.30188245]\n",
      "1.0 [-0.04811335 -0.24182546  0.04036433  0.30188245] False\n",
      "State at 5: [-0.05294985 -0.04730136  0.04640198  0.02219786]\n",
      "1.0 [-0.05294985 -0.04730136  0.04640198  0.02219786] False\n",
      "State at 6: [-0.05389588  0.14712548  0.04684594 -0.2554912 ]\n",
      "1.0 [-0.05389588  0.14712548  0.04684594 -0.2554912 ] False\n",
      "State at 7: [-0.05095337  0.34154835  0.04173611 -0.5330379 ]\n",
      "1.0 [-0.05095337  0.34154835  0.04173611 -0.5330379 ] False\n",
      "State at 8: [-0.04412241  0.53605926  0.03107536 -0.8122833 ]\n",
      "1.0 [-0.04412241  0.53605926  0.03107536 -0.8122833 ] False\n",
      "State at 9: [-0.03340122  0.73074204  0.01482969 -1.0950319 ]\n",
      "1.0 [-0.03340122  0.73074204  0.01482969 -1.0950319 ] False\n",
      "State at 10: [-0.01878638  0.92566556 -0.00707095 -1.3830252 ]\n",
      "1.0 [-0.01878638  0.92566556 -0.00707095 -1.3830252 ] False\n",
      "State at 11: [-2.7306748e-04  7.3063254e-01 -3.4731451e-02 -1.0925618e+00]\n",
      "1.0 [-2.7306748e-04  7.3063254e-01 -3.4731451e-02 -1.0925618e+00] False\n",
      "State at 12: [ 0.01433958  0.53598505 -0.05658269 -0.8109756 ]\n",
      "1.0 [ 0.01433958  0.53598505 -0.05658269 -0.8109756 ] False\n",
      "State at 13: [ 0.02505928  0.34168202 -0.0728022  -0.53661394]\n",
      "1.0 [ 0.02505928  0.34168202 -0.0728022  -0.53661394] False\n",
      "State at 14: [ 0.03189293  0.14765514 -0.08353448 -0.26772955]\n",
      "1.0 [ 0.03189293  0.14765514 -0.08353448 -0.26772955] False\n",
      "State at 15: [ 0.03484603 -0.04618146 -0.08888907 -0.00251908]\n",
      "1.0 [ 0.03484603 -0.04618146 -0.08888907 -0.00251908] False\n",
      "State at 16: [ 0.0339224  -0.2399236  -0.08893945  0.2608478 ]\n",
      "1.0 [ 0.0339224  -0.2399236  -0.08893945  0.2608478 ] False\n",
      "State at 17: [ 0.02912393 -0.4336708  -0.08372249  0.52420616]\n",
      "1.0 [ 0.02912393 -0.4336708  -0.08372249  0.52420616] False\n",
      "State at 18: [ 0.02045051 -0.62752086 -0.07323837  0.78937715]\n",
      "1.0 [ 0.02045051 -0.62752086 -0.07323837  0.78937715] False\n",
      "State at 19: [ 0.00790009 -0.8215647  -0.05745083  1.0581497 ]\n",
      "1.0 [ 0.00790009 -0.8215647  -0.05745083  1.0581497 ] False\n",
      "State at 20: [-0.0085312  -1.0158803  -0.03628783  1.3322611 ]\n",
      "1.0 [-0.0085312  -1.0158803  -0.03628783  1.3322611 ] False\n",
      "State at 21: [-0.02884881 -1.2105265  -0.00964261  1.6133717 ]\n",
      "1.0 [-0.02884881 -1.2105265  -0.00964261  1.6133717 ] False\n",
      "State at 22: [-0.05305934 -1.4055333   0.02262482  1.9030335 ]\n",
      "1.0 [-0.05305934 -1.4055333   0.02262482  1.9030335 ] False\n",
      "State at 23: [-0.08117    -1.2106631   0.06068549  1.617454  ]\n",
      "1.0 [-0.08117    -1.2106631   0.06068549  1.617454  ] False\n",
      "State at 24: [-0.10538326 -1.0163068   0.09303457  1.3442869 ]\n",
      "1.0 [-0.10538326 -1.0163068   0.09303457  1.3442869 ] False\n",
      "State at 25: [-0.1257094  -0.82247     0.11992031  1.082102  ]\n",
      "1.0 [-0.1257094  -0.82247     0.11992031  1.082102  ] False\n",
      "State at 26: [-0.1421588  -0.6291173   0.14156236  0.8293279 ]\n",
      "1.0 [-0.1421588  -0.6291173   0.14156236  0.8293279 ] False\n",
      "State at 27: [-0.15474115 -0.43618488  0.15814891  0.5843047 ]\n",
      "1.0 [-0.15474115 -0.43618488  0.15814891  0.5843047 ] False\n",
      "State at 28: [-0.16346484 -0.24359046  0.169835    0.34532046]\n",
      "1.0 [-0.16346484 -0.24359046  0.169835    0.34532046] False\n",
      "State at 29: [-0.16833666 -0.05124003  0.17674142  0.11063775]\n",
      "1.0 [-0.16833666 -0.05124003  0.17674142  0.11063775] False\n",
      "State at 30: [-0.16936146  0.14096698  0.17895417 -0.12148955]\n",
      "1.0 [-0.16936146  0.14096698  0.17895417 -0.12148955] False\n",
      "State at 31: [-0.16654211  0.33313397  0.17652437 -0.35280463]\n",
      "1.0 [-0.16654211  0.33313397  0.17652437 -0.35280463] False\n",
      "State at 32: [-0.15987943  0.5253641   0.16946828 -0.5850399 ]\n",
      "1.0 [-0.15987943  0.5253641   0.16946828 -0.5850399 ] False\n",
      "State at 33: [-0.14937216  0.71775776  0.15776749 -0.8199107 ]\n",
      "1.0 [-0.14937216  0.71775776  0.15776749 -0.8199107 ] False\n",
      "State at 34: [-0.135017    0.91040957  0.14136927 -1.0591079 ]\n",
      "1.0 [-0.135017    0.91040957  0.14136927 -1.0591079 ] False\n",
      "State at 35: [-0.11680881  1.1034048   0.12018711 -1.3042886 ]\n",
      "1.0 [-0.11680881  1.1034048   0.12018711 -1.3042886 ] False\n",
      "State at 36: [-0.09474071  1.2968152   0.09410134 -1.5570613 ]\n",
      "1.0 [-0.09474071  1.2968152   0.09410134 -1.5570613 ] False\n",
      "State at 37: [-0.06880441  1.4906926   0.06296012 -1.8189658 ]\n",
      "1.0 [-0.06880441  1.4906926   0.06296012 -1.8189658 ] False\n",
      "State at 38: [-0.03899055  1.6850607   0.0265808  -2.0914423 ]\n",
      "1.0 [-0.03899055  1.6850607   0.0265808  -2.0914423 ] False\n",
      "State at 39: [-0.00528934  1.879905   -0.01524805 -2.3757915 ]\n",
      "1.0 [-0.00528934  1.879905   -0.01524805 -2.3757915 ] False\n",
      "State at 40: [ 0.03230876  1.684921   -0.06276388 -2.0878325 ]\n",
      "1.0 [ 0.03230876  1.684921   -0.06276388 -2.0878325 ] False\n",
      "State at 41: [ 0.06600718  1.4904861  -0.10452053 -1.8151947 ]\n",
      "1.0 [ 0.06600718  1.4904861  -0.10452053 -1.8151947 ] False\n",
      "State at 42: [ 0.0958169   1.2966713  -0.14082442 -1.5567322 ]\n",
      "1.0 [ 0.0958169   1.2966713  -0.14082442 -1.5567322 ] False\n",
      "State at 43: [ 0.12175033  1.1034889  -0.17195907 -1.311093  ]\n",
      "1.0 [ 0.12175033  1.1034889  -0.17195907 -1.311093  ] False\n",
      "State at 44: [ 0.1438201   0.9109104  -0.19818093 -1.0767927 ]\n",
      "1.0 [ 0.1438201   0.9109104  -0.19818093 -1.0767927 ] False\n",
      "State at 45: [ 0.16203831  0.7188788  -0.21971677 -0.852268  ]\n",
      "1.0 [ 0.16203831  0.7188788  -0.21971677 -0.852268  ] True\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import gymnasium as gym\n",
    "import random\n",
    "\n",
    "# Initialize environment\n",
    "env = gym.make('CartPole-v1', render_mode = 'rgb_array')\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, env):\n",
    "        self.action_size = env.action_space.n\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        # select a random action\n",
    "        action = random.choice(range(self.action_size))\n",
    "        \n",
    "        # extract a pole angle from state\n",
    "        pole_angle = state[2]\n",
    "\n",
    "        # select action based on the pole angle\n",
    "        # 0 - Push cart to the left \n",
    "        # 1 - Push cart to the right\n",
    "        action = 0 if pole_angle < 0 else 1 \n",
    "        return action\n",
    "\n",
    "agent = Agent(env)\n",
    "state, _ = env.reset()\n",
    "print(\"Reset state: \", state)\n",
    "\n",
    "for i in range(100):\n",
    "    action = agent.get_action(state)\n",
    "    state, reward, done, trunc, info = env.step(action)\n",
    "    print(\"State at %d:\" % i, state)\n",
    "    print(reward,state,done)\n",
    "\n",
    "    if done:\n",
    "        env.reset()\n",
    "        env.close()\n",
    "        break\n",
    "    \n",
    "    env.render()\n",
    "    if reward<1:\n",
    "        sleep(3)\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad044f26-7d8d-457e-ac48-5013ad8ce0d0",
   "metadata": {},
   "source": [
    "### 4. Exercise\n",
    "Implement Q-learning for CartPole task in Gym.<br>\n",
    "\n",
    "There is a sample implementation (but uses outdated packages): <br>\n",
    "https://github.com/nnqomariyah/aima-python/blob/master/gym-cartpole-qlearning.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45905ebd-a56a-4677-8750-2f46175a766d",
   "metadata": {},
   "source": [
    "### 5. References\n",
    "\n",
    "1. Slides for week 7 - Reinforcement Learning\n",
    "2. https://github.com/aimacode/aima-python\n",
    "3. https://github.com/nnqomariyah/aima-python (forked)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a244e0b-05c2-4ef4-b7a8-b4a233f185fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
